{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ths_slj.analysis import backtest, random_monte_test, bh_method\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/846 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "random_monte_test() missing 1 required positional argument: 'm3'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-43-e409f0a6dc2e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0m_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'date'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrandom_monte_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhold_ratio\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m     \u001B[0mbh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m150\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpct_change\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: random_monte_test() missing 1 required positional argument: 'm3'"
     ]
    }
   ],
   "source": [
    "# 测试贝叶斯优化测试集， 能否战胜随机\n",
    "# 训练集，测试集\n",
    "\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "codes = df_train.code.unique()\n",
    "\n",
    "for code in tqdm(codes):\n",
    "    _df = df_test.loc[df_test.code == code].set_index('Unnamed: 0')\n",
    "    _df.index.name = 'date'\n",
    "\n",
    "    res = random_monte_test(df=_df, hold_ratio=0.5, num_iter=100)\n",
    "    bh = _df.close.iloc[150:].pct_change().dropna()\n",
    "\n",
    "    res_bh = (bh.mean()*0.5)/(bh.std()+1e-12)*(252**0.5)\n",
    "    if res is not None:\n",
    "        ps.append((res > res_bh).sum()/len(res))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([387.9       , 258.6       , 189.64      , ...,   0.92071207,\n          0.94036364,   0.94      ]),\n 0)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_method(\n",
    "    np.sort(ps)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.56,\n 0.72,\n 0.46,\n 0.56,\n 0.45,\n 0.59,\n 0.61,\n 0.77,\n 0.57,\n 0.51,\n 0.63,\n 0.43,\n 0.47,\n 0.35,\n 0.52,\n 0.71,\n 0.73,\n 0.39,\n 0.64,\n 0.57,\n 0.5,\n 0.39,\n 0.42,\n 0.42,\n 0.54,\n 0.54,\n 0.6,\n 0.49,\n 0.79,\n 0.58,\n 0.67,\n 0.62,\n 0.29,\n 0.7,\n 0.42,\n 0.59,\n 0.54,\n 0.68,\n 0.65,\n 0.56,\n 0.66,\n 0.6,\n 0.49,\n 0.66,\n 0.6,\n 0.76,\n 0.48,\n 0.5,\n 0.52,\n 0.42,\n 0.43,\n 0.5,\n 0.52,\n 0.53,\n 0.55,\n 0.47,\n 0.71,\n 0.52,\n 0.59,\n 0.39,\n 0.48,\n 0.47,\n 0.42,\n 0.53,\n 0.54,\n 0.44,\n 0.32,\n 0.48,\n 0.48,\n 0.58,\n 0.67,\n 0.41,\n 0.54,\n 0.55,\n 0.54,\n 0.35,\n 0.48,\n 0.51,\n 0.54,\n 0.6,\n 0.54,\n 0.74,\n 0.74,\n 0.47,\n 0.54,\n 0.43,\n 0.57,\n 0.62,\n 0.62,\n 0.52,\n 0.61,\n 0.48,\n 0.44,\n 0.69,\n 0.6,\n 0.82,\n 0.54,\n 0.59,\n 0.34,\n 0.51,\n 0.51,\n 0.35,\n 0.53,\n 0.48,\n 0.59,\n 0.43,\n 0.4,\n 0.7,\n 0.65,\n 0.42,\n 0.62,\n 0.45,\n 0.68,\n 0.35,\n 0.73,\n 0.8,\n 0.64,\n 0.5,\n 0.8,\n 0.57,\n 0.49,\n 0.78,\n 0.72,\n 0.79,\n 0.69,\n 0.31,\n 0.37,\n 0.55,\n 0.58,\n 0.65,\n 0.53,\n 0.61,\n 0.58,\n 0.54,\n 0.42,\n 0.61,\n 0.56,\n 0.7,\n 0.39,\n 0.58,\n 0.57,\n 0.65,\n 0.67,\n 0.56,\n 0.6,\n 0.61,\n 0.66,\n 0.63,\n 0.59,\n 0.49,\n 0.82,\n 0.65,\n 0.43,\n 0.66,\n 0.51,\n 0.5,\n 0.54,\n 0.5,\n 0.47,\n 0.54,\n 0.59,\n 0.44,\n 0.72,\n 0.41,\n 0.72,\n 0.46,\n 0.62,\n 0.6,\n 0.6,\n 0.5,\n 0.56,\n 0.45,\n 0.57,\n 0.75,\n 0.41,\n 0.54,\n 0.72,\n 0.38,\n 0.7,\n 0.33,\n 0.67,\n 0.47,\n 0.51,\n 0.66,\n 0.44,\n 0.66,\n 0.46,\n 0.59,\n 0.57,\n 0.78,\n 0.58,\n 0.66,\n 0.57,\n 0.66,\n 0.48,\n 0.7,\n 0.51,\n 0.68,\n 0.54,\n 0.49,\n 0.5,\n 0.44,\n 0.53,\n 0.53,\n 0.32,\n 0.71,\n 0.57,\n 0.65,\n 0.54,\n 0.59,\n 0.49,\n 0.56,\n 0.61,\n 0.69,\n 0.55,\n 0.41,\n 0.72,\n 0.57,\n 0.51,\n 0.57,\n 0.41,\n 0.54,\n 0.42,\n 0.7,\n 0.48,\n 0.57,\n 0.59,\n 0.64,\n 0.76,\n 0.66,\n 0.56,\n 0.5,\n 0.46,\n 0.6,\n 0.7,\n 0.53,\n 0.67,\n 0.63,\n 0.42,\n 0.66,\n 0.54,\n 0.43,\n 0.6,\n 0.51,\n 0.5,\n 0.57,\n 0.53,\n 0.68,\n 0.53,\n 0.7,\n 0.58,\n 0.72,\n 0.65,\n 0.83,\n 0.71,\n 0.57,\n 0.48,\n 0.55,\n 0.55,\n 0.15,\n 0.57,\n 0.63,\n 0.39,\n 0.76,\n 0.51,\n 0.59,\n 0.47,\n 0.76,\n 0.71,\n 0.66,\n 0.54,\n 0.39,\n 0.22,\n 0.51,\n 0.59,\n 0.77,\n 0.71,\n 0.5,\n 0.69,\n 0.73,\n 0.71,\n 0.65,\n 0.47,\n 0.43,\n 0.58,\n 0.32,\n 0.71,\n 0.54,\n 0.39,\n 0.6,\n 0.63,\n 0.48,\n 0.63,\n 0.55,\n 0.67,\n 0.69,\n 0.56,\n 0.54,\n 0.54,\n 0.55,\n 0.4,\n 0.61,\n 0.66,\n 0.54,\n 0.64,\n 0.33,\n 0.6,\n 0.6,\n 0.7,\n 0.67,\n 0.49,\n 0.33,\n 0.72,\n 0.68,\n 0.48,\n 0.68,\n 0.51,\n 0.43,\n 0.57,\n 0.56,\n 0.41,\n 0.63,\n 0.46,\n 0.64,\n 0.62,\n 0.64,\n 0.38,\n 0.77,\n 0.57,\n 0.71,\n 0.67,\n 0.73,\n 0.63,\n 0.53,\n 0.33,\n 0.59,\n 0.63,\n 0.5,\n 0.34,\n 0.62,\n 0.6,\n 0.4,\n 0.27,\n 0.62,\n 0.42,\n 0.65,\n 0.7,\n 0.45,\n 0.68,\n 0.71,\n 0.52,\n 0.44,\n 0.67,\n 0.6,\n 0.62,\n 0.53,\n 0.59,\n 0.57,\n 0.63,\n 0.59,\n 0.61,\n 0.54,\n 0.71,\n 0.53,\n 0.55,\n 0.54,\n 0.82,\n 0.71,\n 0.69,\n 0.57,\n 0.64,\n 0.59,\n 0.62,\n 0.64,\n 0.54,\n 0.53,\n 0.62,\n 0.6,\n 0.56,\n 0.64,\n 0.81,\n 0.59,\n 0.72,\n 0.59,\n 0.6,\n 0.57,\n 0.59,\n 0.59,\n 0.29,\n 0.82,\n 0.47,\n 0.46,\n 0.68,\n 0.57,\n 0.34,\n 0.47,\n 0.6,\n 0.67,\n 0.69,\n 0.66,\n 0.38,\n 0.58,\n 0.33,\n 0.55,\n 0.43,\n 0.51,\n 0.61,\n 0.42,\n 0.54,\n 0.64,\n 0.55,\n 0.48,\n 0.37,\n 0.43,\n 0.69,\n 0.69,\n 0.55,\n 0.45,\n 0.66,\n 0.44,\n 0.65,\n 0.72,\n 0.68,\n 0.69,\n 0.42,\n 0.61,\n 0.48,\n 0.75,\n 0.84,\n 0.45,\n 0.67,\n 0.37,\n 0.52,\n 0.65,\n 0.87,\n 0.41,\n 0.59,\n 0.58,\n 0.37,\n 0.47,\n 0.7,\n 0.49,\n 0.53,\n 0.6,\n 0.57,\n 0.56,\n 0.55,\n 0.38,\n 0.4,\n 0.51,\n 0.51,\n 0.66,\n 0.67,\n 0.44,\n 0.57,\n 0.55,\n 0.76,\n 0.52,\n 0.82,\n 0.53,\n 0.62,\n 0.36,\n 0.67,\n 0.61,\n 0.59,\n 0.52,\n 0.65,\n 0.47,\n 0.68,\n 0.74,\n 0.59,\n 0.66,\n 0.36,\n 0.72,\n 0.54,\n 0.51,\n 0.36,\n 0.64,\n 0.48,\n 0.52,\n 0.42,\n 0.58,\n 0.64,\n 0.67,\n 0.74,\n 0.44,\n 0.65,\n 0.57,\n 0.72,\n 0.65,\n 0.4,\n 0.4,\n 0.57,\n 0.27,\n 0.58,\n 0.86,\n 0.51,\n 0.55,\n 0.61,\n 0.59,\n 0.49,\n 0.57,\n 0.53,\n 0.55,\n 0.56,\n 0.48,\n 0.44,\n 0.48,\n 0.45,\n 0.57,\n 0.54,\n 0.54,\n 0.61,\n 0.63,\n 0.48,\n 0.52,\n 0.54,\n 0.56,\n 0.48,\n 0.52,\n 0.56,\n 0.53,\n 0.47,\n 0.52,\n 0.57,\n 0.4,\n 0.59,\n 0.52,\n 0.49,\n 0.57,\n 0.58,\n 0.48,\n 0.57,\n 0.42,\n 0.49,\n 0.57,\n 0.52,\n 0.55,\n 0.59,\n 0.55,\n 0.52,\n 0.52,\n 0.44,\n 0.54,\n 0.6,\n 0.52,\n 0.56,\n 0.54,\n 0.55,\n 0.54,\n 0.56,\n 0.56,\n 0.52,\n 0.46,\n 0.62,\n 0.51,\n 0.48,\n 0.54,\n 0.47,\n 0.49,\n 0.62,\n 0.56,\n 0.61,\n 0.57,\n 0.46,\n 0.5,\n 0.54,\n 0.55,\n 0.42,\n 0.55,\n 0.52,\n 0.43,\n 0.54,\n 0.53,\n 0.56,\n 0.53,\n 0.58,\n 0.59,\n 0.52,\n 0.59,\n 0.51,\n 0.46,\n 0.54,\n 0.53,\n 0.4,\n 0.57,\n 0.52,\n 0.51,\n 0.6,\n 0.56,\n 0.53,\n 0.5,\n 0.41,\n 0.58,\n 0.45,\n 0.56,\n 0.47,\n 0.53,\n 0.6,\n 0.51,\n 0.49,\n 0.48,\n 0.57,\n 0.52,\n 0.59,\n 0.55,\n 0.6,\n 0.51,\n 0.51,\n 0.57,\n 0.5,\n 0.52,\n 0.52,\n 0.46,\n 0.58,\n 0.53,\n 0.54,\n 0.46,\n 0.53,\n 0.59,\n 0.62,\n 0.48,\n 0.48,\n 0.52,\n 0.48,\n 0.55,\n 0.5,\n 0.5,\n 0.63,\n 0.52,\n 0.53,\n 0.48,\n 0.59,\n 0.46,\n 0.5,\n 0.56,\n 0.5,\n 0.52,\n 0.48,\n 0.52,\n 0.44,\n 0.57,\n 0.44,\n 0.46,\n 0.49,\n 0.58,\n 0.6,\n 0.47,\n 0.52,\n 0.58,\n 0.55,\n 0.45,\n 0.53,\n 0.39,\n 0.55,\n 0.46,\n 0.56,\n 0.64,\n 0.57,\n 0.54,\n 0.48,\n 0.55,\n 0.55,\n 0.55,\n 0.55,\n 0.58,\n 0.54,\n 0.43,\n 0.49,\n 0.47,\n 0.45,\n 0.49,\n 0.53,\n 0.56,\n 0.5,\n 0.53,\n 0.51,\n 0.48,\n 0.59,\n 0.44,\n 0.51,\n 0.63,\n 0.49,\n 0.48,\n 0.5,\n 0.51,\n 0.55,\n 0.55,\n 0.53,\n 0.47,\n 0.59,\n 0.47,\n 0.55,\n 0.53,\n 0.49,\n 0.55,\n 0.55,\n 0.53,\n 0.6,\n 0.41,\n 0.5,\n 0.51,\n 0.4,\n 0.59,\n 0.52,\n 0.41,\n 0.61,\n 0.44,\n 0.47,\n 0.62,\n 0.52,\n 0.51,\n 0.46,\n 0.5,\n 0.54,\n 0.48,\n 0.53,\n 0.47,\n 0.63,\n 0.56,\n 0.45,\n 0.46,\n 0.5,\n 0.56,\n 0.57,\n 0.62,\n 0.52,\n 0.52,\n 0.55,\n 0.55,\n 0.56,\n 0.59,\n 0.49,\n 0.57,\n 0.57,\n 0.57,\n 0.53,\n 0.48,\n 0.5,\n 0.49,\n 0.46,\n 0.43,\n 0.47,\n 0.46,\n 0.66,\n 0.6,\n 0.49,\n 0.5,\n 0.46,\n 0.61,\n 0.48,\n 0.36,\n 0.61,\n 0.52,\n 0.53,\n 0.63,\n 0.55,\n 0.3,\n 0.4,\n 0.56,\n 0.47,\n 0.54,\n 0.52,\n 0.48,\n 0.42,\n 0.68,\n 0.37,\n 0.58,\n 0.43,\n 0.47,\n 0.38,\n 0.58,\n 0.61,\n 0.48,\n 0.68,\n 0.55,\n 0.45,\n 0.5,\n 0.52,\n 0.38,\n 0.63,\n 0.3,\n 0.51,\n 0.53,\n 0.43,\n 0.62,\n 0.58,\n 0.53,\n 0.51,\n 0.52,\n 0.49,\n 0.62,\n 0.5,\n 0.51,\n 0.49,\n 0.4,\n 0.58,\n 0.7,\n 0.58,\n 0.58,\n 0.52,\n 0.59,\n 0.57,\n 0.44,\n 0.74,\n 0.38,\n 0.34,\n 0.66,\n 0.38,\n 0.55,\n 0.47,\n 0.6,\n 0.57,\n 0.62,\n 0.62,\n 0.4,\n 0.53,\n 0.42,\n 0.45,\n 0.52,\n 0.57,\n 0.56,\n 0.5,\n 0.64,\n 0.56,\n 0.55,\n 0.7,\n 0.47,\n 0.46,\n 0.59,\n 0.53,\n 0.61,\n 0.46,\n 0.57,\n 0.64,\n 0.66,\n 0.45,\n 0.53,\n 0.51,\n 0.46,\n 0.67,\n 0.59,\n 0.63,\n 0.5,\n 0.5,\n 0.58,\n 0.4,\n 0.53,\n 0.58,\n 0.54,\n 0.62,\n 0.53,\n 0.59,\n 0.5,\n 0.55,\n 0.57,\n 0.6,\n 0.64,\n 0.6,\n 0.48,\n 0.54,\n 0.33,\n 0.6,\n 0.5,\n 0.6,\n 0.44,\n 0.64,\n 0.51,\n 0.52,\n 0.37,\n 0.31,\n 0.5,\n 0.58,\n 0.54,\n 0.71,\n 0.38,\n 0.54,\n 0.55,\n 0.58,\n 0.65,\n 0.27,\n 0.49,\n 0.38,\n 0.44,\n 0.66,\n 0.68,\n 0.54,\n 0.55,\n 0.58,\n 0.54,\n 0.61,\n 0.46,\n 0.62,\n 0.42,\n 0.4,\n 0.46,\n 0.59,\n 0.69,\n 0.5,\n 0.38,\n 0.47,\n 0.55,\n 0.6,\n 0.61,\n 0.46,\n 0.55,\n 0.48,\n 0.7,\n 0.53,\n 0.52,\n 0.66,\n 0.64,\n 0.38,\n 0.52,\n 0.51,\n 0.46,\n 0.65,\n 0.53,\n 0.49,\n 0.61,\n 0.55,\n 0.56,\n 0.56,\n 0.65,\n 0.57,\n 0.52,\n 0.59,\n 0.58,\n 0.69,\n 0.53,\n 0.52,\n 0.54,\n 0.46,\n 0.45,\n 0.54,\n 0.59,\n 0.62,\n 0.31,\n 0.51,\n 0.47,\n 0.49,\n 0.49,\n 0.56,\n 0.56,\n 0.67,\n 0.6,\n 0.56,\n 0.33,\n 0.33,\n 0.68,\n 0.42,\n 0.57,\n 0.52,\n 0.49,\n 0.54,\n 0.34,\n 0.66,\n 0.48,\n 0.43,\n 0.64,\n 0.55,\n 0.31,\n 0.33,\n 0.58,\n 0.45,\n 0.55,\n 0.29,\n 0.53,\n 0.55,\n 0.42,\n 0.41,\n 0.51,\n 0.34,\n 0.44,\n 0.47,\n 0.49,\n 0.62,\n 0.58,\n 0.51,\n 0.59,\n 0.28,\n 0.51,\n 0.63,\n 0.37,\n 0.43,\n 0.53,\n 0.37,\n 0.56,\n 0.71,\n 0.45,\n 0.55,\n 0.63,\n 0.38,\n 0.44,\n 0.42,\n 0.48,\n 0.39,\n 0.56,\n 0.54,\n 0.73,\n ...]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for code in tqdm(codes):\n",
    "    _df = df_train.loc[df_train.code == code].set_index('Unnamed: 0')\n",
    "    _df.index.name = 'date'\n",
    "    # todo 贝叶斯优化\n",
    "\n",
    "\n",
    "\n",
    "    bh = _df.close.iloc[150:].pct_change().dropna()\n",
    "\n",
    "    res_bh = (bh.mean()*0.5)/(bh.std()+1e-12)*(252**0.5)\n",
    "\n",
    "    res = random_monte_test(df=_df, hold_ratio=0.5, num_iter=100)\n",
    "    if res is not None:\n",
    "        ps.append((res > res_bh).sum()/len(res))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}